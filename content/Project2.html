---
title: 'Project 2: Modeling, Testing, and Predicting'
author: "Lindsay Collier (lmc3746)"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

<script src="/rmarkdown-libs/kePrint/kePrint.js"></script>


<div id="introduction" class="section level3">
<h3>Introduction</h3>
<p>For this project, I will be building a predictive model using a dataset that compiles characteristics of individual web users who did or did not click on an ad. This dataset, <em>ad</em>, contains the binary response variable ‘clicked on ad,’ quantified as either a 0 (did not click) or a 1 (did click). The dataset additionally includes the following variables: daily time spent on the website (in minutes), daily internet usage (in minutes), age, area income ($), and gender.</p>
<table class="table" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:right;">
clicked
</th>
<th style="text-align:left;">
gender
</th>
<th style="text-align:right;">
age
</th>
<th style="text-align:right;">
income
</th>
<th style="text-align:right;">
daily_site_time
</th>
<th style="text-align:right;">
daily_internet_time
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
0
</td>
<td style="text-align:left;">
female
</td>
<td style="text-align:right;">
35
</td>
<td style="text-align:right;">
61833.90
</td>
<td style="text-align:right;">
68.95
</td>
<td style="text-align:right;">
256.09
</td>
</tr>
<tr>
<td style="text-align:right;">
0
</td>
<td style="text-align:left;">
male
</td>
<td style="text-align:right;">
31
</td>
<td style="text-align:right;">
68441.85
</td>
<td style="text-align:right;">
80.23
</td>
<td style="text-align:right;">
193.77
</td>
</tr>
<tr>
<td style="text-align:right;">
0
</td>
<td style="text-align:left;">
female
</td>
<td style="text-align:right;">
26
</td>
<td style="text-align:right;">
59785.94
</td>
<td style="text-align:right;">
69.47
</td>
<td style="text-align:right;">
236.50
</td>
</tr>
<tr>
<td style="text-align:right;">
0
</td>
<td style="text-align:left;">
male
</td>
<td style="text-align:right;">
29
</td>
<td style="text-align:right;">
54806.18
</td>
<td style="text-align:right;">
74.15
</td>
<td style="text-align:right;">
245.89
</td>
</tr>
<tr>
<td style="text-align:right;">
0
</td>
<td style="text-align:left;">
female
</td>
<td style="text-align:right;">
35
</td>
<td style="text-align:right;">
73889.99
</td>
<td style="text-align:right;">
68.37
</td>
<td style="text-align:right;">
225.58
</td>
</tr>
<tr>
<td style="text-align:right;">
0
</td>
<td style="text-align:left;">
male
</td>
<td style="text-align:right;">
23
</td>
<td style="text-align:right;">
59761.56
</td>
<td style="text-align:right;">
59.99
</td>
<td style="text-align:right;">
226.74
</td>
</tr>
</tbody>
</table>
</div>
<div id="testing-variables" class="section level3">
<h3>Testing Variables</h3>
<p>To see which numeric variables, if any, explained any significant variation in the response variable (whether a user clicked on an ad), a MANOVA test was performed.</p>
<pre><code>## Df Pillai approx F num Df den Df Pr(&gt;F)
## clicked 1 0.82322 1158.4 4 995 &lt; 2.2e-16 ***
## Residuals 998
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1</code></pre>
<p>The results of the MANOVA show that there are significant differences in the four dependent measures (daily time spent on site, daily internet usage, area income, and age) across the two levels of the “clicked on ad” variable, with a p-value &lt;0.05.</p>
<p>Univariate ANOVAs were performed on each of the four dependent variables.</p>
<pre><code>## Response daily_site_time :
## Df Sum Sq Mean Sq F value Pr(&gt;F)
## clicked 1 140527 140527 1268.5 &lt; 2.2e-16 ***
## Residuals 998 110558 111
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1
##
## Response age :
## Df Sum Sq Mean Sq F value Pr(&gt;F)
## clicked 1 18706 18705.6 319.64 &lt; 2.2e-16 ***
## Residuals 998 58403 58.5
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1
##
## Response income :
## Df Sum Sq Mean Sq F value Pr(&gt;F)
## clicked 1 4.0776e+10 4.0776e+10 292.77 &lt; 2.2e-16 ***
## Residuals 998 1.3900e+11 1.3928e+08
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1
##
## Response daily_internet_time :
## Df Sum Sq Mean Sq F value Pr(&gt;F)
## clicked 1 1191191 1191191 1619 &lt; 2.2e-16 ***
## Residuals 998 734297 736
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1</code></pre>
<p>All four responses showed significant mean differences across the two groups of the “clicked on ad” variable, with a p-value &lt;0.05. Post hoc analysis of these four variables was consistent with the univariate ANOVAs, in that each response variable was shown to significantly differ across the binary groups (0 or 1) of the “clicked on ad” variable.</p>
<p>For this analysis, 9 tests were performed (1 MANOVA, 4 ANOVAs, and 4 t-tests). The probability of type I error is 36.98%. The Bonferroni correction is thus 0.05/9 = 0.0056. Even after incorporating this Bonferroni adjustment, each numeric variable differs significantly across the two levels of the “clicked on ad” variable.</p>
</div>
<div id="randomization-test" class="section level3">
<h3>Randomization Test</h3>
<p>In addition to the MANOVA above, I performed a randomization MANOVA test on this data and tested the following null hypothesis:</p>
<p>H<sub>0</sub>: Whether a user clicked on an ad does not vary by age, income, daily time spent on a site, and daily time spent on the internet.</p>
<p>H<sub>A</sub>: Whether a user clicked on an ad does vary by age, income, daily time spent on a site, and daily time spent on the internet.</p>
<p><img src="/Project2_files/figure-html/unnamed-chunk-6-1.png" width="768" style="display: block; margin: auto;" /></p>
<p>The observed F-value (red line) is significantly larger than the null distribution, visualized above. As such, I can conclude that the response variable (‘clicked’) varies significantly by the descriptive variables analyzed here (age, income, daily time spent on a site, and daily time spent on the internet).</p>
</div>
<div id="linear-regression-model" class="section level3">
<h3>Linear Regression Model</h3>
<p>First, I built a linear model predicting daily time spent on a site by area income and gender.</p>
<pre><code>##
## Call:
## lm(formula = daily_site_time ~ income * gender, data =
ad)
##
## Residuals:
## Min 1Q Median 3Q Max
## -32.10 -11.88 1.48 12.30 32.43
##
## Coefficients:
## Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) 2.953e-01 6.622e-01 0.446 0.656
## income 3.622e-04 4.774e-05 7.587 7.47e-14 ***
## gendermale -6.141e-01 9.549e-01 -0.643 0.520
## income:gendermale 1.196e-05 7.161e-05 0.167 0.867
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1
##
## Residual standard error: 15.09 on 996 degrees of freedom
## Multiple R-squared: 0.09709, Adjusted R-squared: 0.09437
## F-statistic: 35.7 on 3 and 996 DF, p-value: &lt; 2.2e-16</code></pre>
<p><img src="/Project2_files/figure-html/unnamed-chunk-7-1.png" width="768" style="display: block; margin: auto;" /></p>
<p>After running the linear model, the coefficient estimate for the income variable is 3.6 x 10<sup>-4</sup>, the coefficient estimate for the gender variable is -1.27, and the coefficient estimate for the interaction between income and gender is 1.2 x 10<sup>-5</sup>.</p>
<p>For males, for each unit increase in income, the average daily time spent on a site increases by 3.72 x 10<sup>-4</sup>. For females, for each unit increase in income, the average daily time spent on a site increases by 3.6 x 10<sup>-4</sup>. Additionally, males’ average daily time spent on a site is 1.27 units less than females’.</p>
<p><img src="/Project2_files/figure-html/unnamed-chunk-8-1.png" width="768" style="display: block; margin: auto;" /><img src="/Project2_files/figure-html/unnamed-chunk-8-2.png" width="768" style="display: block; margin: auto;" /></p>
<p>To test the homoskedasticity assumption, I performed a Breusch-Pagan test, and computed a p-value &lt; 0.05. Thus, the null hypothesis of homoskedasticity was thus rejected, and the data is heteroskedastic. To test the linearity assumption, I plotted the fitted values against the residuals, and concluded that the data was not scattered randomly arround the mean, and thus the data is not linear. Finally, to test the normality assumption, I plotted a qq-plot and concluded that the data is not normally distributed.</p>
<p>Because the data used in this model fails the homoskedasticity assumption, I re-ran the regression results with robust standard errors.</p>
<pre><code>##
## t test of coefficients:
##
## Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) 2.9527e-01 6.5071e-01 0.4538 0.6501
## income 3.6220e-04 4.0383e-05 8.9693 &lt;2e-16 ***
## gendermale -6.1409e-01 9.5775e-01 -0.6412 0.5216
## income:gendermale 1.1962e-05 6.2122e-05 0.1926 0.8473
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1</code></pre>
<p>I observed that the significance of the analyzed variables did not change: the income variable was found to have a significant positive relationship with daily time spent on a site, but gender and the interaction between gender and income were not found to be significant. The proportion of variation in the outcome explained by this linear model is 9.7%.</p>
</div>
<div id="linear-regression-model-with-bootstrapped-standard-errors" class="section level3">
<h3>Linear Regression Model with Bootstrapped Standard Errors</h3>
<p>I decided to compute bootstrapped standard errors for this linear model and compare them to the previously-computed standard errors, in order to identify any significant differences.</p>
<pre><code>##   (Intercept)       income gendermale income:gendermale
## 1   0.6619255 4.778763e-05  0.9546957       7.17491e-05</code></pre>
<p>The values of the bootstrapped standard errors for each coefficient estimate do not differ very much from the non-bootstrapped standard errors.</p>
<p>I additionally computed bootstrapped p-values for the model’s coefficient estimates and found them to also be relatively similar to the non-bootstrapped estimates.</p>
<pre><code>##   (Intercept)       income gendermale income:gendermale
## 1   0.4715552 5.529616e-09  0.4352809          0.537234</code></pre>
<p>The bootstrapped p-value for the ‘income’ coefficient is larger than the non-bootstrapped p-value, though it is still significant. The bootstrapped p-values for the ‘gender’ variable and the interaction between ‘gender’ and ‘income’ are both insignificant.</p>
</div>
<div id="logisitic-regression-model" class="section level3">
<h3>Logisitic Regression Model</h3>
<p>Because the linear regression model proved to be a poor predictor for this dataset, I then constructed a logistic regression model to predict whether a user will click on an ad, using income and age as predictors.</p>
<pre><code>##
## Call:
## glm(formula = clicked ~ income + age, family =
&quot;binomial&quot;, data = ad)
##
## Deviance Residuals:
## Min 1Q Median 3Q Max
## -3.2167 -0.7125 -0.1286 0.6214 2.4354
##
## Coefficients:
## Estimate Std. Error z value Pr(&gt;|z|)
## (Intercept) 2.670e-01 9.002e-02 2.966 0.00302 **
## income -1.033e-04 8.207e-06 -12.586 &lt; 2e-16 ***
## age 1.626e-01 1.261e-02 12.901 &lt; 2e-16 ***
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1
##
## (Dispersion parameter for binomial family taken to be 1)
##
## Null deviance: 1386.3 on 999 degrees of freedom
## Residual deviance: 880.0 on 997 degrees of freedom
## AIC: 886
##
## Number of Fisher Scoring iterations: 5</code></pre>
<p>After running this model, both coefficients were found to be significant, with p-values &lt; 0.05. For every 1 unit increase in income, the odds of a user clicking on ad decrease by e<sup>-1.03 x 10<sup>-4</sup></sup>. For every 1 unit increase in age, the odds of a user clicking on an ad increase by e<sup>0.163</sup>.</p>
<pre><code>##      prediction
## truth    0    1  Sum
##   0    430   70  500
##   1    121  379  500
##   Sum  551  449 1000</code></pre>
<p>This logistic model’s diagnostic statistics are decent. The model has an accuracy of 0.809, a sensitivity of 0.844, a specificity of 0.780, and a recall of 0.758. Thus, this model has a high proportion of correctly classified cases and accurate predictions.</p>
<p>I constructed a logit density plot and an ROC curve for this model, as seen below.</p>
<p><img src="/Project2_files/figure-html/unnamed-chunk-14-1.png" width="768" style="display: block; margin: auto;" /><img src="/Project2_files/figure-html/unnamed-chunk-14-2.png" width="768" style="display: block; margin: auto;" /></p>
<p>This model has an AUC of 0.874. This means that there is a 87.4% probability that a randomly selected person who clicked on an ad has a higher prediction value than a randomly selected person who did not click on ad.</p>
<p>10-fold cross-validation was performed to compute this model’s out-of-sample performance.</p>
<pre><code>##       acc      sens       ppv 
## 0.8070000 0.7617276 0.8396749</code></pre>
<p>The out-of-sample accuracy is 0.807, its sensitivity is 0.762, and its recall is 0.840. Ultimately, these diagnostic statistics are similar to the model’s in-sample performance, and thus I can conclude that this simple logistic model is a reliable predictor of the outcome variable.</p>
</div>
<div id="lasso-regression-model" class="section level3">
<h3>LASSO Regression Model</h3>
<p>To improve the logistic model’s performance, I performed LASSO on the entire dataset to select the most important variables to incorporate into the logistic model.</p>
<pre><code>## 7 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
##                              s0
## (Intercept)          0.50000000
## income              -0.06227066
## age                  0.05945539
## daily_site_time     -0.18871586
## daily_internet_time -0.22082342
## genderfemale         .         
## gendermale           .</code></pre>
<pre><code>##       acc      sens       ppv 
## 0.9670000 0.9570238 0.9775518</code></pre>
<p>After running a Lasso regression, the variables that were retained are age, income, daily time spent on a site, and daily time spent on the internet. The gender variable was dropped.</p>
<p>10-fold cross-validation was performed on a new model containing only Lasso-selected variables, and it was found that this new model’s out-of-sample accuracy was greatly improved over the previous logistic model. This model has an accuracy of 0.967, a sensitivity of 0.957, and a recall of 0.978. Ultimately, this logistic regression model (with variable selection performed by LASSO) can reliably predict whether a user will click on ad by using the predictors income, age, daily site time, and daily internet time.</p>
</div>
